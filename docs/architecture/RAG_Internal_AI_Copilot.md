
# ğŸ§  RAG-based AI Copilot for Internal Knowledge â€“ On-Prem Deployment (No GPU)

## âœ… 1. Má»¥c tiÃªu há»‡ thá»‘ng
XÃ¢y dá»±ng má»™t há»‡ thá»‘ng trá»£ lÃ½ AI ná»™i bá»™ cÃ³ kháº£ nÄƒng:
- Tráº£ lá»i cÃ¢u há»i tá»± nhiÃªn dá»±a trÃªn tÃ i liá»‡u cÃ´ng ty (PDF, Word, Excel, SharePointâ€¦)
- KhÃ´ng sá»­ dá»¥ng cloud LLM â€“ Ä‘áº£m báº£o dá»¯ liá»‡u **khÃ´ng rÃ² rá»‰**
- CÃ³ thá»ƒ má»Ÿ rá»™ng lÃªn nhiá»u ngÆ°á»i dÃ¹ng

---

## ğŸ—ï¸ 2. Kiáº¿n trÃºc tá»•ng thá»ƒ

```mermaid
flowchart TD
  subgraph "NgÆ°á»i dÃ¹ng"
    A["ğŸ’¬ Giao diá»‡n Chat<br/>(Web / CLI / Internal Chatbot)"]
  end

  subgraph "RAG Engine"
    B["â“ CÃ¢u há»i Ä‘áº§u vÃ o"] --> C["ğŸ” Vector Retriever<br/>(FAISS / Chroma)"]
    C --> D["ğŸ“„ Káº¿t quáº£ truy xuáº¥t<br/>(3-5 Ä‘oáº¡n)"]
    D --> E["ğŸ§  LLM ná»™i bá»™<br/>(phi-3 / mistral)"]
    E --> F["ğŸ“ CÃ¢u tráº£ lá»i"]
  end

  subgraph "Data Pipeline (offline)"
    G["ğŸ“‚ TÃ i liá»‡u<br/>(PDF, Excel, Word...)"]
    G --> H["ğŸ”¨ Chunk + Embedding<br/>LangChain + MiniLM"]
    H --> C
  end

  A --> B
  F --> A
```

---

## âš™ï¸ 3. ThÃ nh pháº§n chÃ­nh

| ThÃ nh pháº§n | CÃ´ng nghá»‡ gá»£i Ã½ | Vai trÃ² |
|------------|------------------|---------|
| LLM ná»™i bá»™ | [`Ollama`](https://ollama.com) + `phi-3`, `mistral` | Sinh cÃ¢u tráº£ lá»i, cháº¡y báº±ng CPU |
| Embedding | `Instructor`, `all-MiniLM-L6-v2`, `BGE` | Biáº¿n Ä‘oáº¡n vÄƒn thÃ nh vector |
| Vector DB | `Chroma`, `FAISS` | LÆ°u trá»¯ vector tÃ¬m kiáº¿m |
| Document Loader | LangChain: `PyPDFLoader`, `DocxLoader`, `PandasLoader` | Äá»c & xá»­ lÃ½ tÃ i liá»‡u Ä‘áº§u vÃ o |
| Giao diá»‡n ngÆ°á»i dÃ¹ng | `Streamlit`, `Gradio`, hoáº·c Web Chat | Chat vá»›i RAG agent |
| Orchestration | `LangChain RetrievalQA` / `ConversationalRetrievalChain` | Xá»­ lÃ½ pipeline truy váº¥n |

---

### ğŸ“ MÃ´ táº£ chi tiáº¿t cÃ¡c thÃ nh pháº§n chÃ­nh

#### 1. Ollama (Local LLM Runner)
- **Chá»©c nÄƒng:** Ná»n táº£ng cháº¡y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) trÃªn mÃ¡y chá»§ ná»™i bá»™, há»— trá»£ nhiá»u model (phi-3, mistral, llama...).
- **Kiáº¿n trÃºc:** ÄÃ³ng vai trÃ² nhÆ° backend LLM, cung cáº¥p API phá»¥c vá»¥ truy váº¥n sinh ngÃ´n ngá»¯ tá»± nhiÃªn.
- **LÃ½ do chá»n:** Dá»… triá»ƒn khai, há»— trá»£ CPU, khÃ´ng cáº§n GPU, mÃ£ nguá»“n má»Ÿ, báº£o máº­t dá»¯ liá»‡u ná»™i bá»™.
- **So sÃ¡nh:** So vá»›i LM Studio, llama.cpp: Ollama dá»… dÃ¹ng hÆ¡n, há»— trá»£ nhiá»u model, cÃ³ REST API chuáº©n.

#### 2. phi-3, mistral (MÃ´ hÃ¬nh LLM)
- **Chá»©c nÄƒng:** Sinh cÃ¢u tráº£ lá»i tá»± Ä‘á»™ng tá»« dá»¯ liá»‡u Ä‘Ã£ truy xuáº¥t.
- **Kiáº¿n trÃºc:** ÄÆ°á»£c táº£i vÃ  phá»¥c vá»¥ qua Ollama, tá»‘i Æ°u cho inference trÃªn CPU.
- **LÃ½ do chá»n:** Nháº¹, tá»‘c Ä‘á»™ tá»‘t, cháº¥t lÆ°á»£ng tráº£ lá»i cao, mÃ£ nguá»“n má»Ÿ.
- **So sÃ¡nh:** So vá»›i Llama 2, GPT-J: phi-3/mistral nháº¹ hÆ¡n, dá»… deploy on-prem, khÃ´ng cáº§n GPU.

#### 3. Chroma, FAISS (Vector Database)
- **Chá»©c nÄƒng:** LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m vector embedding cá»§a tÃ i liá»‡u.
- **Kiáº¿n trÃºc:** Cháº¡y local, tÃ­ch há»£p tá»‘t vá»›i LangChain, há»— trá»£ tÃ¬m kiáº¿m semantic.
- **LÃ½ do chá»n:** CÃ i Ä‘áº·t Ä‘Æ¡n giáº£n, hiá»‡u nÄƒng cao, mÃ£ nguá»“n má»Ÿ, khÃ´ng cáº§n dá»‹ch vá»¥ cloud.
- **So sÃ¡nh:** So vá»›i Pinecone, Weaviate: Chroma/FAISS khÃ´ng cáº§n cloud, miá»…n phÃ­, dá»… tÃ­ch há»£p Python.

#### 4. Instructor, MiniLM, BGE (Embedding Model)
- **Chá»©c nÄƒng:** Biáº¿n Ä‘oáº¡n vÄƒn báº£n thÃ nh vector sá»‘ Ä‘á»ƒ tÃ¬m kiáº¿m semantic.
- **Kiáº¿n trÃºc:** Cháº¡y local, tÃ­ch há»£p vá»›i pipeline embedding cá»§a LangChain.
- **LÃ½ do chá»n:** Nháº¹, tá»‘c Ä‘á»™ nhanh, cháº¥t lÆ°á»£ng embedding tá»‘t, mÃ£ nguá»“n má»Ÿ.
- **So sÃ¡nh:** So vá»›i OpenAI Embedding: KhÃ´ng cáº§n cloud/API key, báº£o máº­t dá»¯ liá»‡u.

#### 5. LangChain (Orchestration)
- **Chá»©c nÄƒng:** Äiá»u phá»‘i pipeline RAG: load tÃ i liá»‡u, chunk, embedding, truy váº¥n, tá»•ng há»£p káº¿t quáº£.
- **Kiáº¿n trÃºc:** Framework Python, há»— trá»£ nhiá»u thÃ nh pháº§n plug-and-play.
- **LÃ½ do chá»n:** Cá»™ng Ä‘á»“ng lá»›n, tÃ i liá»‡u tá»‘t, dá»… má»Ÿ rá»™ng, tÃ­ch há»£p nhiá»u backend.
- **So sÃ¡nh:** So vá»›i LlamaIndex: LangChain phá»• biáº¿n hÆ¡n, nhiá»u vÃ­ dá»¥ thá»±c táº¿ hÆ¡n.

#### 6. Gradio, Streamlit (Giao diá»‡n ngÆ°á»i dÃ¹ng)
- **Chá»©c nÄƒng:** Táº¡o giao diá»‡n chat web nhanh chÃ³ng cho ngÆ°á»i dÃ¹ng ná»™i bá»™.
- **Kiáº¿n trÃºc:** Cháº¡y local, dá»… deploy, há»— trá»£ nhiá»u tÃ­nh nÄƒng UI.
- **LÃ½ do chá»n:** Dá»… dÃ¹ng, mÃ£ nguá»“n má»Ÿ, khÃ´ng cáº§n backend phá»©c táº¡p.
- **So sÃ¡nh:** So vá»›i FastAPI, Flask: Gradio/Streamlit dá»±ng UI nhanh, khÃ´ng cáº§n code HTML/JS.

---

## ğŸ” 4. Báº£o máº­t & dá»¯ liá»‡u

- **KhÃ´ng dÃ¹ng API OpenAI** â†’ KhÃ´ng rÃ² rá»‰ dá»¯ liá»‡u
- LLM, embedding, vector store **cháº¡y toÃ n bá»™ on-prem**
- KhÃ´ng gá»­i báº¥t ká»³ ná»™i dung nÃ o ra internet
- CÃ³ thá»ƒ phÃ¢n quyá»n truy cáº­p theo ngÆ°á»i dÃ¹ng náº¿u tÃ­ch há»£p vá»›i há»‡ thá»‘ng ná»™i bá»™

---

## ğŸ§ª 5. YÃªu cáº§u há»‡ thá»‘ng

| ThÃ nh pháº§n | Má»©c tá»‘i thiá»ƒu |
|------------|---------------|
| RAM | 16 GB (khuyáº¿n nghá»‹ 32 GB) |
| CPU | i5 Gen8 / Ryzen 5 trá»Ÿ lÃªn |
| Disk | SSD â‰¥ 30 GB |
| OS | Windows / macOS / Ubuntu |
| GPU | âŒ KhÃ´ng cáº§n |

---

## ğŸš€ 6. CÃ¡ch triá»ƒn khai (chi tiáº¿t)

### ğŸŸ¢ Giai Ä‘oáº¡n 1: Proof of Concept (Tuáº§n 1)
- [ ] CÃ i Ä‘áº·t Ollama + LangChain + FAISS/Chroma
- [ ] Chá»n 10 tÃ i liá»‡u ná»™i bá»™ (PDF, Excelâ€¦)
- [ ] Táº¡o script embedding & chunk tÃ i liá»‡u
- [ ] XÃ¢y giao diá»‡n chat (Gradio / CLI)
- [ ] Demo ná»™i bá»™, kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c

### ğŸŸ¡ Giai Ä‘oáº¡n 2: Rollout ná»™i bá»™ (Tuáº§n 2â€“3)
- [ ] Äá»“ng bá»™ tÃ i liá»‡u tá»« thÆ° má»¥c dÃ¹ng chung / SharePoint
- [ ] Tá»± Ä‘á»™ng cáº­p nháº­t vector store
- [ ] Triá»ƒn khai lÃªn server ná»™i bá»™ (hoáº·c VPS riÃªng)
- [ ] Giao diá»‡n thÃ¢n thiá»‡n (chat history, user context)

### ğŸ”µ Giai Ä‘oáº¡n 3: Má»Ÿ rá»™ng & tÃ­ch há»£p (Tuáº§n 4+)
- [ ] Gáº¯n vá»›i chatbot ná»™i bá»™ (MS Teams, Zalo, Slackâ€¦)
- [ ] PhÃ¢n quyá»n ngÆ°á»i dÃ¹ng (náº¿u cÃ³ SSO)
- [ ] Export bÃ¡o cÃ¡o tÆ°Æ¡ng tÃ¡c
- [ ] Theo dÃµi log truy váº¥n & Ä‘á»™ chÃ­nh xÃ¡c

---

## ğŸ“¦ 7. TÃ i liá»‡u Ä‘áº§u vÃ o há»— trá»£

| Äá»‹nh dáº¡ng | ÄÆ°á»£c há»— trá»£? | Ghi chÃº |
|----------|---------------|--------|
| PDF | âœ… | TÃ¡ch theo trang hoáº·c Ä‘oáº¡n |
| DOCX | âœ… | DÃ¹ng `DocxLoader` |
| Excel | âœ… | DÃ¹ng `PandasLoader` hoáº·c chuyá»ƒn CSV |
| SharePoint | âœ… | Sync qua API hoáº·c mount thÆ° má»¥c |
| Google Drive | âš ï¸ | Cáº§n API OAuth2 |
| Database | âœ… | Truy váº¥n SQL â†’ chunk ná»™i dung |

---

##  8. Æ¯á»›c tÃ­nh chi phÃ­ (ná»™i bá»™ â€“ khÃ´ng cloud)

| Má»¥c | Chi phÃ­ |
|-----|---------|
| Pháº§n má»m | âœ… 100% mÃ£ nguá»“n má»Ÿ |
| Server ná»™i bá»™ / VPS | 30â€“100 USD/thÃ¡ng (tÃ¹y RAM & á»• Ä‘Ä©a) |
| NhÃ¢n sá»± setup | 1 ká»¹ sÆ° (internal hoáº·c freelance) |
| LÆ°u trá»¯ dá»¯ liá»‡u | Dá»±a theo kÃ­ch thÆ°á»›c PDF/Excel â€“ khÃ´ng Ä‘Ã¡ng ká»ƒ |
| TÄƒng trÆ°á»Ÿng | Scale báº±ng thÃªm RAM/disk, khÃ´ng cáº§n GPU |

---

## ğŸ“ 9. Má»Ÿ rá»™ng trong tÆ°Æ¡ng lai

- âœ… Gáº¯n agent vá»›i há»‡ thá»‘ng bÃ¡o cÃ¡o Power BI / dashboard ná»™i bá»™
- âœ… Cho phÃ©p táº£i thÃªm tÃ i liá»‡u qua giao diá»‡n
- âœ… LÆ°u lá»‹ch sá»­ truy váº¥n
- âœ… ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ chÃ­nh xÃ¡c tráº£ lá»i (feedback)
- âœ… Gáº¯n chatbot vÃ o á»©ng dá»¥ng CRM, ERP, HRM

---

## ğŸ“Œ 10. TÃ i liá»‡u tham kháº£o

- [LangChain Docs](https://docs.langchain.com/)
- [Ollama â€“ Local LLM Runner](https://ollama.com)
- [Instructor Embedding](https://huggingface.co/hkunlp/instructor-xl)
- [Chroma Vector DB](https://www.trychroma.com/)

---

## ğŸ“© Gá»£i Ã½ tiáº¿p theo

- Báº¯t Ä‘áº§u thá»­ vá»›i 10â€“20 file PDF tá»« phÃ²ng káº¿ toÃ¡n, phÃ¡p cháº¿ hoáº·c váº­n hÃ nh
- DÃ¹ng `ollama run mistral` + `langchain` Ä‘á»ƒ RAG máº«u
- Náº¿u cáº§n, yÃªu cáº§u bá»™ **repo máº«u cháº¡y ngay** tá»« mÃ¬nh

---

## ğŸ“‘ Phá»¥ lá»¥c: So sÃ¡nh Chroma vÃ  Supabase (pgvector) cho Vector Database

| TiÃªu chÃ­                | Chroma                                 | Supabase (pgvector)                      |
|-------------------------|----------------------------------------|------------------------------------------|
| Báº£n cháº¥t                | Vector DB thuáº§n tÃºy, mÃ£ nguá»“n má»Ÿ       | Backend Ä‘a nÄƒng, dá»±a trÃªn PostgreSQL     |
| Triá»ƒn khai              | Local/on-prem, pip install             | Cloud hoáº·c self-hosted, cáº¥u hÃ¬nh phá»©c táº¡p |
| TÃ­ch há»£p                | Python API, LangChain                  | REST API, GraphQL, SDK Ä‘a ná»n táº£ng       |
| TÃ­nh nÄƒng               | TÃ¬m kiáº¿m semantic, metadata            | Vector search + DB, auth, storage, ...   |
| Báº£o máº­t                 | Dá»¯ liá»‡u ná»™i bá»™, khÃ´ng cloud            | PhÃ¢n quyá»n user, audit log, cloud option |
| Quáº£n lÃ½ user/role       | KhÃ´ng                                  | CÃ³                                       |
| Hiá»‡u nÄƒng vector search | Cao, tá»‘i Æ°u cho RAG nhá» gá»n            | Phá»¥ thuá»™c cáº¥u hÃ¬nh PostgreSQL            |
| Chi phÃ­                 | Miá»…n phÃ­, khÃ´ng cloud                  | CÃ³ thá»ƒ phÃ¡t sinh phÃ­ cloud               |
| Äá»™ phá»©c táº¡p sá»­ dá»¥ng     | ÄÆ¡n giáº£n, nhanh gá»n                    | Äa nÄƒng, cáº¥u hÃ¬nh phá»©c táº¡p hÆ¡n           |

**TÃ³m táº¯t lá»±a chá»n:**
- **Chroma:** PhÃ¹ há»£p cho RAG ná»™i bá»™, báº£o máº­t, Ä‘Æ¡n giáº£n, thuáº§n Python.
- **Supabase (pgvector):** PhÃ¹ há»£p náº¿u cáº§n backend tá»•ng thá»ƒ (DB, auth, storage), REST API, hoáº·c Ä‘Ã£ dÃ¹ng PostgreSQL.

---

## âš¡ Hiá»‡u nÄƒng há»‡ thá»‘ng (Performance)

### 1. Hiá»‡u nÄƒng LLM (Ollama + phi-3/mistral)
- **TrÃªn CPU (khÃ´ng GPU):**
  - phi-3/mistral 7B: tá»‘c Ä‘á»™ sinh **5â€“15 token/giÃ¢y** trÃªn CPU phá»• thÃ´ng (i5 Gen8/Ryzen 5, 16â€“32GB RAM).
  - MÃ¡y chá»§ máº¡nh hÆ¡n (nhiá»u core, RAM lá»›n): **15â€“25 token/giÃ¢y**.
- **So sÃ¡nh:** GPU cÃ³ thá»ƒ Ä‘áº¡t 30â€“60 token/giÃ¢y, nhÆ°ng thiáº¿t káº¿ nÃ y tá»‘i Æ°u cho CPU.

### 2. Hiá»‡u nÄƒng Vector Search (Chroma/FAISS)
- TÃ¬m kiáº¿m semantic trÃªn 1,000â€“10,000 chunk: **<1 giÃ¢y** (local, RAM).
- Sá»‘ chunk lá»›n (hÃ ng trÄƒm nghÃ¬n): 1â€“2 giÃ¢y.
- Tá»‘c Ä‘á»™ embedding (MiniLM): ~1,000â€“2,000 Ä‘oáº¡n/phÃºt trÃªn CPU.

### 3. Tá»•ng thá»ƒ pipeline RAG
- Má»™t truy váº¥n hoÃ n chá»‰nh (retrieval + LLM):
  - Retrieval: **<1 giÃ¢y**
  - LLM sinh cÃ¢u tráº£ lá»i:
    - 50 token: ~4â€“10 giÃ¢y
    - 100 token: ~10â€“20 giÃ¢y
  - Tá»•ng thá»i gian tráº£ lá»i: **5â€“20 giÃ¢y** tuá»³ Ä‘á»™ dÃ i cÃ¢u tráº£ lá»i

### 4. CÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng
- Sá»‘ user Ä‘á»“ng thá»i: hiá»‡u nÄƒng giáº£m tuyáº¿n tÃ­nh theo sá»‘ core CPU
- KÃ­ch thÆ°á»›c tÃ i liá»‡u: cÃ ng nhiá»u chunk, RAM/CPU cÃ ng tá»‘n
- CÃ³ thá»ƒ tá»‘i Æ°u báº±ng: giáº£m sá»‘ token, tá»‘i Æ°u prompt, chá»‰ láº¥y top-3 chunk, batch embedding

### 5. Káº¿t luáº­n thá»±c táº¿ cho PoC
- Tá»‘c Ä‘á»™ sinh token: **5â€“15 token/giÃ¢y** (CPU)
- Tá»‘c Ä‘á»™ tráº£ lá»i truy váº¥n: **10â€“20 giÃ¢y** (cÃ¢u dÃ i), **5â€“10 giÃ¢y** (cÃ¢u ngáº¯n)
- TÃ¬m kiáº¿m vector: **<1 giÃ¢y** vá»›i <10,000 chunk
- PhÃ¹ há»£p cho PoC, demo ná»™i bá»™, 1â€“5 user Ä‘á»“ng thá»i

### 6. Äo benchmark thá»±c táº¿
- Äo tá»‘c Ä‘á»™ sinh token: `ollama run mistral:7b --timing`
- Äo thá»i gian truy váº¥n vector: log thá»i gian trÆ°á»›c/sau khi gá»i FAISS/Chroma
