# ğŸ”„ US-002 Document Processing Pipeline - Overview

**Epic**: 1 - Proof of Concept  
**User Story**: US-002 - Document Processing Pipeline  
**Purpose**: Chuyá»ƒn Ä‘á»•i tÃ i liá»‡u thÃ´ thÃ nh dá»¯ liá»‡u sáºµn sÃ ng cho AI

---

## ğŸ¤” **Pipeline lÃ  gÃ¬?**

**Pipeline** (Ä‘Æ°á»ng á»‘ng xá»­ lÃ½) lÃ  má»™t chuá»—i cÃ¡c bÆ°á»›c xá»­ lÃ½ dá»¯ liá»‡u Ä‘Æ°á»£c káº¿t ná»‘i vá»›i nhau, trong Ä‘Ã³ output cá»§a bÆ°á»›c nÃ y trá»Ÿ thÃ nh input cá»§a bÆ°á»›c tiáº¿p theo.

### **ğŸ­ KhÃ¡i niá»‡m Pipeline**

HÃ¬nh dung nhÆ° má»™t **dÃ¢y chuyá»n sáº£n xuáº¥t**:
- **Input**: NguyÃªn liá»‡u thÃ´ vÃ o Ä‘áº§u dÃ¢y chuyá»n
- **Processing Steps**: CÃ¡c tráº¡m gia cÃ´ng khÃ¡c nhau
- **Output**: Sáº£n pháº©m hoÃ n chá»‰nh ra cuá»‘i dÃ¢y chuyá»n

```
\[Raw Data\] â†’ \[Step 1\] â†’ \[Step 2\] â†’ \[Step 3\] â†’ \[Final Output\]
```

### **ğŸ¯ Táº¡i sao cáº§n Pipeline?**

#### **âœ… Lá»£i Ã­ch:**

1. **Modularity**: Má»—i step Ä‘á»™c láº­p, cÃ³ thá»ƒ test riÃªng
2. **Reusability**: CÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng cho documents khÃ¡c
3. **Scalability**: Dá»… má»Ÿ rá»™ng thÃªm steps
4. **Maintainability**: Dá»… debug vÃ  sá»­a lá»—i
5. **Quality Control**: Validate tá»«ng step

#### **ğŸ¯ VÃ­ dá»¥ thá»±c táº¿:**

**âŒ KhÃ´ng cÃ³ Pipeline:**
```python
# Táº¥t cáº£ logic trong 1 file khá»•ng lá»“
def process_everything(file):
    # 500 lines of mixed logic
    # Hard to debug
    # Hard to reuse
    # Hard to test
```

**âœ… CÃ³ Pipeline:**
```python
# Chia nhá» thÃ nh cÃ¡c steps
def step1_process(file): ...
def step2_chunk(data): ...
def step3_metadata(chunks): ...
def step4_storage(enhanced): ...

# Dá»… test, debug, maintain
```

---

## ğŸ”§ **US-002 Document Processing Pipeline**

### **ğŸ“Š Tá»•ng quan luá»“ng xá»­ lÃ½:**

```
\[MD File\] â†’ \[Process\] â†’ \[Chunk\] â†’ \[Metadata\] â†’ \[Storage\] â†’ \[Ready for AI\]
```

### **ğŸ¯ Chi tiáº¿t tá»«ng bÆ°á»›c:**

#### **Step 1: Input** ğŸ“„
```
Input: AI-Starter-Kit.md (raw markdown file)
- Size: ~15KB
- Format: Markdown vá»›i syntax, headers, lists
- Content: Há»—n há»£p text, code, formatting
```

#### **Step 2: Document Processing** ğŸ”
```
Script: process_md.py
Input:  Raw markdown
Output: Clean text + metadata

CÃ´ng viá»‡c:
- Loáº¡i bá» markdown syntax
- TrÃ­ch xuáº¥t metadata (title, headers, stats)
- LÃ m sáº¡ch ná»™i dung
- Táº¡o file: AI-Starter-Kit_processed.json
```

#### **Step 3: Text Chunking** âœ‚ï¸
```
Script: simple_chunk.py
Input:  Clean text
Output: Text chunks

CÃ´ng viá»‡c:
- Chia text thÃ nh chunks 200-800 tokens
- Äáº£m báº£o khÃ´ng cáº¯t giá»¯a cÃ¢u
- Tá»‘i Æ°u cho embedding
- Táº¡o file: AI-Starter-Kit_simple_chunked.json
```

#### **Step 4: Metadata Enhancement** ğŸ·ï¸
```
Script: extract_metadata.py
Input:  Text chunks
Output: Enhanced chunks

CÃ´ng viá»‡c:
- PhÃ¢n loáº¡i content type
- TrÃ­ch xuáº¥t keywords
- PhÃ¢n tÃ­ch structure
- Táº¡o file: AI-Starter-Kit_with_metadata.json
```

#### **Step 5: Data Storage** ğŸ’¾
```
Script: save_processed_data.py
Input:  Enhanced chunks
Output: Multiple formats

CÃ´ng viá»‡c:
- JSON, CSV, Pickle formats
- Embedding-ready format
- Search indexes
- Táº¡o thÆ° má»¥c: AI-Starter-Kit_final_output/
```

#### **Step 6: Ready for US-003** ğŸš€
```
Output: embedding_ready.json
- 4 chunks sáºµn sÃ ng cho vector embedding
- Metadata Ä‘áº§y Ä‘á»§
- Format chuáº©n cho AI models
```

#### **Step 7: Quality Check** ğŸ”
```
Script: prepare_embedding.py
Input:  Final output directory
Output: Quality validation + config

CÃ´ng viá»‡c:
- Validate embedding_ready.json format
- Kiá»ƒm tra UTF-8 encoding
- PhÃ¢n tÃ­ch content statistics
- Táº¡o embedding_config.json
```

#### **Step 8: Pipeline Testing** ğŸ§ª
```
Script: test_pipeline.py
Input:  MD file
Output: Complete validation report

CÃ´ng viá»‡c:
- Test end-to-end pipeline (Steps 1-7)
- Validate táº¥t cáº£ intermediate files
- Kiá»ƒm tra quality check results
- Táº¡o comprehensive test report
```

---

## ğŸ—ï¸ **Kiáº¿n trÃºc Pipeline**

### **ğŸ“ Cáº¥u trÃºc thÆ° má»¥c:**
```
/opt/rag-copilot/
â”œâ”€â”€ scripts/           # Pipeline steps
â”‚   â”œâ”€â”€ process_md.py          # Step 1: Document Processing
â”‚   â”œâ”€â”€ simple_chunk.py        # Step 2: Text Chunking
â”‚   â”œâ”€â”€ extract_metadata.py    # Step 3: Metadata Enhancement
â”‚   â”œâ”€â”€ save_processed_data.py # Step 4: Data Storage
â”‚   â”œâ”€â”€ test_pipeline.py       # End-to-end testing
â”‚   â””â”€â”€ prepare_embedding.py   # US-003 preparation
â”œâ”€â”€ docs/              # Input documents
â”œâ”€â”€ output/            # Intermediate & final outputs
â””â”€â”€ logs/              # Processing logs
```

### **ğŸ”„ Data Flow:**
```
AI-Starter-Kit.md
    â†“ (process_md.py)
AI-Starter-Kit_processed.json
    â†“ (simple_chunk.py)
AI-Starter-Kit_simple_chunked.json
    â†“ (extract_metadata.py)
AI-Starter-Kit_with_metadata.json
    â†“ (save_processed_data.py)
AI-Starter-Kit_final_output/
    â”œâ”€â”€ embedding_ready.json â† Quan trá»ng nháº¥t
    â”œâ”€â”€ chunks_summary.csv
    â”œâ”€â”€ search_index.json
    â”œâ”€â”€ processed_data.pkl
    â”œâ”€â”€ processing_report.json
    â””â”€â”€ AI-Starter-Kit_complete.json
```

---

## ğŸš€ **Pipeline vs Single Script**

### **âŒ Single Script Problems:**
- **Monolithic**: Táº¥t cáº£ logic trong 1 file
- **Hard to debug**: Lá»—i á»Ÿ Ä‘Ã¢u khÃ³ tÃ¬m
- **No reusability**: KhÃ´ng tÃ¡i sá»­ dá»¥ng Ä‘Æ°á»£c
- **No checkpoints**: Lá»—i pháº£i cháº¡y láº¡i tá»« Ä‘áº§u
- **Hard to test**: KhÃ³ test tá»«ng pháº§n riÃªng
- **Difficult maintenance**: KhÃ³ maintain code

### **âœ… Pipeline Benefits:**
- **Modular**: Má»—i step riÃªng biá»‡t
- **Easy debugging**: Lá»—i á»Ÿ step nÃ o rÃµ rÃ ng
- **Reusable**: CÃ³ thá»ƒ dÃ¹ng láº¡i tá»«ng step
- **Checkpoints**: CÃ³ thá»ƒ resume tá»« step bá»‹ lá»—i
- **Easy testing**: Test tá»«ng step Ä‘á»™c láº­p
- **Maintainable**: Dá»… maintain vÃ  update

---

## ğŸ¯ **Pipeline trong AI/ML Context**

### **ğŸ“Š Typical ML Pipeline:**
```
Raw Data â†’ Clean â†’ Feature Engineering â†’ Model Training â†’ Evaluation â†’ Deployment
```

### **ğŸ” RAG Pipeline:**
```
Documents â†’ Processing â†’ Chunking â†’ Embedding â†’ Vector Store â†’ Retrieval â†’ Generation
```

### **ğŸ­ Our Pipeline Position:**
```
\[US-002: Document Processing\] â†’ \[US-003: Vector Embedding\] â†’ \[US-004: RAG System\]
```

---

## ğŸ“Š **Thá»‘ng kÃª Pipeline US-002**

### **Input:**
- **File**: AI-Starter-Kit.md
- **Size**: ~15KB
- **Content**: 1,731 words, 56 headings

### **Processing:**
- **Steps**: 6 main steps
- **Scripts**: 7 Python scripts
- **Time**: <10 seconds total

### **Output:**
- **Chunks**: 4 chunks
- **Tokens**: 1,847 total tokens
- **Average**: 461 tokens per chunk
- **Files**: 6 different output formats

### **Quality Metrics:**
- **Chunk Size Range**: 200-800 tokens âœ…
- **Metadata Coverage**: 100% âœ…
- **Content Classification**: 100% âœ…
- **UTF-8 Encoding**: 100% âœ…
- **JSON Validation**: 100% âœ…

---

## ğŸ”§ **CÃ¡ch cháº¡y Pipeline**

### **ğŸ§ª End-to-End Test:**
```bash
# Test toÃ n bá»™ pipeline
python3.8 /opt/rag-copilot/scripts/test_pipeline.py /path/to/your/document.md

# Kiá»ƒm tra káº¿t quáº£
ls -la /opt/rag-copilot/output/
cat /opt/rag-copilot/logs/pipeline_test_*.log
```

### **âš™ï¸ Run tá»«ng Step:**
```bash
# Step 1: Process MD
python3.8 /opt/rag-copilot/scripts/process_md.py /path/to/document.md

# Step 2: Chunking
python3.8 /opt/rag-copilot/scripts/simple_chunk.py /opt/rag-copilot/output/document_processed.json

# Step 3: Metadata
python3.8 /opt/rag-copilot/scripts/extract_metadata.py /opt/rag-copilot/output/document_simple_chunked.json

# Step 4: Storage
python3.8 /opt/rag-copilot/scripts/save_processed_data.py /opt/rag-copilot/output/document_with_metadata.json
```

---

## ğŸ¯ **Káº¿t quáº£ quan trá»ng**

### **ğŸ“„ embedding_ready.json** - File quan trá»ng nháº¥t
```json
{
  "documents": \[
    "This guide will help you set up...",
    "The AI Starter Kit provides...",
    "Installation steps include...",
    "Configuration options are..."
  \],
  "metadata": \[
    \{"chunk_id": "chunk_0", "source_file": "AI-Starter-Kit.md", "content_type": "instruction"\},
    \{"chunk_id": "chunk_1", "source_file": "AI-Starter-Kit.md", "content_type": "overview"\},
    \{"chunk_id": "chunk_2", "source_file": "AI-Starter-Kit.md", "content_type": "instruction"\},
    \{"chunk_id": "chunk_3", "source_file": "AI-Starter-Kit.md", "content_type": "configuration"\}
  \],
  "ids": \["chunk_0", "chunk_1", "chunk_2", "chunk_3"\]
}
```

### **ğŸš€ Ready for US-003:**
- âœ… **4 chunks** sáºµn sÃ ng cho vector embedding
- âœ… **Metadata Ä‘áº§y Ä‘á»§** vá»›i content classification
- âœ… **Format chuáº©n** cho embedding models
- âœ… **UTF-8 encoding** Ä‘áº£m báº£o

---

## ğŸ’¡ **TÃ³m táº¯t**

**Pipeline** lÃ :
- âœ… **Chuá»—i xá»­ lÃ½** tá»« input Ä‘áº¿n output
- âœ… **Chia nhá»** cÃ´ng viá»‡c phá»©c táº¡p thÃ nh steps Ä‘Æ¡n giáº£n
- âœ… **Tá»± Ä‘á»™ng hÃ³a** quy trÃ¬nh xá»­ lÃ½
- âœ… **Äáº£m báº£o cháº¥t lÆ°á»£ng** qua validation tá»«ng step
- âœ… **Dá»… maintain** vÃ  scale

**US-002 Pipeline** chuyá»ƒn Ä‘á»•i:
```
Raw Markdown â†’ AI-Ready Data
```

**Káº¿t quáº£**: 4 chunks sáºµn sÃ ng cho US-003 Vector Embedding! ğŸ¯

---

**Document Created**: 2025-07-10 18:30  
**Created By**: Bob the Scrum Master  
**Next Phase**: US-003 Vector Embedding Pipeline 