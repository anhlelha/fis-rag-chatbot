#!/usr/bin/env python3.8
"""
Debug Ollama Connection
Check Ollama service and model availability
"""

import sys
import json

def debug_ollama():
    """Debug Ollama connection"""
    print("üîç Debugging Ollama connection...")
    
    # Check if ollama module is available
    try:
        import ollama
        print("‚úÖ ollama module imported successfully")
    except ImportError as e:
        print(f"‚ùå Cannot import ollama: {e}")
        print("Install with: pip3.8 install ollama")
        return False
    
    # Test connection
    try:
        client = ollama.Client(host='http://localhost:11434')
        print("‚úÖ Ollama client created")
        
        # Test list models
        print("\nüìã Testing model list...")
        models = client.list()
        print(f"Raw response: {models}")
        
        if not models:
            print("‚ùå Empty response from Ollama")
            return False
        
        if 'models' not in models:
            print("‚ùå 'models' key not found in response")
            print("Response keys:", list(models.keys()) if isinstance(models, dict) else "Not a dict")
            return False
        
        model_list = models['models']
        print(f"‚úÖ Found {len(model_list)} models")
        
        if not model_list:
            print("‚ùå No models available")
            print("Pull a model with: ollama pull mistral:7b")
            return False
        
        print("\nüìö Available models:")
        for i, model in enumerate(model_list):
            print(f"  {i+1}. {model}")
            if isinstance(model, dict):
                name = model.get('name', 'unknown')
                size = model.get('size', 'unknown')
                print(f"     Name: {name}")
                print(f"     Size: {size}")
        
        # Check for mistral model
        print(f"\nüîç Checking for mistral:7b model...")
        mistral_found = False
        for model in model_list:
            model_name = model.get('name', '') if isinstance(model, dict) else str(model)
            if 'mistral' in model_name.lower():
                print(f"‚úÖ Found Mistral model: {model_name}")
                mistral_found = True
        
        if not mistral_found:
            print("‚ùå Mistral model not found")
            print("Pull with: ollama pull mistral:7b")
            return False
        
        # Test simple generation
        print(f"\nüß™ Testing simple generation...")
        try:
            response = client.generate(
                model='mistral:7b',
                prompt='Hello, how are you?',
                options={'num_predict': 10}
            )
            print("‚úÖ Generation test successful")
            print(f"Response: {response.get('response', 'No response')[:100]}...")
            
        except Exception as e:
            print(f"‚ùå Generation test failed: {e}")
            return False
        
        print("\n‚úÖ All Ollama checks passed!")
        return True
        
    except Exception as e:
        print(f"‚ùå Ollama connection failed: {e}")
        print("\nTroubleshooting:")
        print("1. Check if Ollama service is running: systemctl status ollama")
        print("2. Check if port 11434 is open: netstat -tlnp | grep 11434")
        print("3. Try manual connection: curl http://localhost:11434/api/tags")
        return False

if __name__ == "__main__":
    success = debug_ollama()
    sys.exit(0 if success else 1) 